use alloc::{sync::Arc, vec::Vec};

use axfs_ng_vfs::{FileNode, FileNodeOps, VfsResult};
use lru::LruCache;

use super::PAGE_SIZE;
use crate::{CachedFile, PageCache, highlevel::file::CachedFileShared};

// TODO: u32? or u64
/// default max page size (128KB / 4KB = 32 pages)
pub const RA_MAX_PAGES: u32 = 32;

/// default min page size (prevent too small IO)
pub const RA_MIN_PAGES: u32 = 2; // Linux VM_MIN_READAHEAD

/// ramp up initial scale factor
const INIT_RA_SCALE: u32 = 4;

/// ramp up factor for subsequent readahead
const RAMP_UP_SCALE: u32 = 2;

pub struct ReadaheadState {
    pub start_pn: u32,
    pub size: u32,
    pub async_size: u32,
    pub prev_pn: u32,
    pub max_pages: u32,
}

impl ReadaheadState {
    pub const fn new(max_pages: u32) -> Self {
        Self {
            start_pn: 0,
            size: 0, // disabled readahead for now
            async_size: 0,
            prev_pn: 0,
            max_pages,
        }
    }

    /// update readahead window on cache miss
    /// # Warnings
    /// the window size should never be 0
    /// # Returns
    /// readahead range (start_pn, size, pg_readahead_offset) if need to trigger readahead
    /// Otherwise, None
    pub fn update_window_on_cache_miss(
        &mut self,
        trigger_pn: u32,
        req_size: u32,
    ) -> Option<(u32, u32, u32)> {
        // sequential access, although didn't hit PG_readahead
        // or initial access,
        // or large read request, that is worth readahead
        if trigger_pn == self.prev_pn + 1
            || trigger_pn == self.prev_pn
            || trigger_pn == 0
            || req_size > self.max_pages
        {
            let mut new_size = Self::init_ra_size(req_size, self.max_pages);
            if self.size > 0 {
                new_size = new_size.saturating_mul(RAMP_UP_SCALE).min(self.max_pages);
            }
            self.start_pn = trigger_pn;
            self.async_size = self.size;
            self.size = new_size;
            return Some((trigger_pn, new_size, self.get_trigger_offset()));
        }

        // random access, reset readahead window
        self.size = 0;
        self.async_size = 0;
        None
    }

    // NOTE: these codes are generated by copilot
    // ---------------------------------------------------------------
    /// 分支 2: 后续预读 (Subsequent Readahead / Ramp Up)
    /// 触发场景: 命中 PG_readahead 标记
    /// 论文来源:
    pub fn update_window_for_async(&mut self) {
        // 1. 推进窗口起点: 新起点 = 旧起点 + 旧大小
        assert!(self.size > 0, "Readahead window size should never be 0");
        self.start_pn = self.start_pn.saturating_add(self.size);
        // 2. 指数倍增: size = prev_size * 2
        let mut new_size = self.size.saturating_mul(RAMP_UP_SCALE);
        // 3. 限制上限
        new_size = new_size.min(self.max_pages);
        // 4. 更新大小
        self.size = new_size;
        // 5. 保持流水线: async_size = size
        self.async_size = new_size;
    }

    /// [辅助] 获取需要打上 PG_readahead 标记的页号
    /// 公式: start + size - async_size
    pub const fn get_trigger_offset(&self) -> u32 {
        if self.size == 0 {
            return 0; // 此时不应该打标
        }
        self.start_pn + self.size - self.async_size
    }

    /// [辅助] 在 read 结束时更新 prev_pn
    pub const fn update_history(&mut self, last_read_pn: u32) {
        self.prev_pn = last_read_pn;
    }

    const fn init_ra_size(req_size: u32, max_pages: u32) -> u32 {
        let mut size = req_size.saturating_mul(INIT_RA_SCALE);
        if size < RA_MIN_PAGES {
            size = RA_MIN_PAGES;
        } else if size > max_pages {
            size = max_pages;
        }
        size
    }
    // end of copilot generated code
    // ---------------------------------------------------------------
}

pub(super) trait Readahead {
    /// find cache from cache
    fn find_page_from_cache<'a>(
        &self,
        caches: &'a mut LruCache<u32, PageCache>,
        pn: u32,
    ) -> Option<(&'a mut PageCache, Option<u32>)>;
}

// TODO: terrible performance when request size is small
impl Readahead for CachedFile {
    fn find_page_from_cache<'a>(
        &self,
        caches: &'a mut LruCache<u32, PageCache>,
        pn: u32,
    ) -> Option<(&'a mut PageCache, Option<u32>)> {
        caches.get_mut(&pn).map(|cache| {
            let mut new_pg_pn = None;
            if cache.pg_readahead {
                cache.pg_readahead = false;
                let mut ra = self.ra_state.lock();
                if ra.size > 0 {
                    ra.update_window_for_async();
                    new_pg_pn = Some(ra.get_trigger_offset());
                }
            }
            (cache, new_pg_pn)
        })
    }
}

pub fn async_prefetch(
    cache_shared: Arc<CachedFileShared>,
    file: Arc<dyn FileNodeOps>,
    in_memory: bool,
    start_pn: u32,
    size: u32,
    async_pg_pn: u32,
) {
    let _ = io_submit(
        &cache_shared,
        &FileNode::new(file),
        in_memory,
        start_pn,
        size,
        async_pg_pn,
    );
}

pub fn io_submit(
    cache_shared: &CachedFileShared,
    file: &FileNode,
    in_memory: bool,
    start_pn: u32,
    size: u32,
    async_pg_pn: u32,
) -> VfsResult<()> {
    let mut pages_to_read = Vec::with_capacity(size as usize);
    {
        let caches = cache_shared.page_cache.lock();
        for pn in start_pn..(start_pn + size) {
            if caches.contains(&pn) {
                continue;
            }
            pages_to_read.push(pn);
        }
    }

    // lockless load pages
    let mut loaded_pages = Vec::with_capacity(pages_to_read.len());
    for &pn in &pages_to_read {
        let mut page = PageCache::new()?;

        if pn == async_pg_pn {
            page.pg_readahead = true;
        }

        if in_memory {
            page.data().fill(0);
        } else {
            file.read_at(page.data(), pn as u64 * PAGE_SIZE as u64)?;
        }
        loaded_pages.push((pn, page));
    }

    let mut caches = cache_shared.page_cache.lock();
    for (pn, page) in loaded_pages {
        if caches.contains(&pn) {
            continue;
        }

        if caches.len() == caches.cap().get() {
            if let Some((evict_pn, mut evicted_page)) = caches.pop_lru() {
                drop(caches);
                let _ = cache_shared.evict_cache(file, evict_pn, &mut evicted_page);
                caches = cache_shared.page_cache.lock();
            }
        }
        caches.put(pn, page);
    }
    Ok(())
}
