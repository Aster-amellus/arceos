use alloc::sync::Arc;

use axfs_ng_vfs::{FileNode, FileNodeOps, VfsResult};
use lru::LruCache;

use super::PAGE_SIZE;
use crate::{CachedFile, PageCache, highlevel::file::CachedFileShared};

// TODO: u32? or u64
/// default max page size (128KB / 4KB = 32 pages)
pub const RA_MAX_PAGES: u32 = 32;

/// default min page size (prevent too small IO)
pub const RA_MIN_PAGES: u32 = 2; // Linux VM_MIN_READAHEAD

/// ramp up initial scale factor
const INIT_RA_SCALE: u32 = 4;

/// ramp up factor for subsequent readahead
const RAMP_UP_SCALE: u32 = 2;

pub struct ReadaheadState {
    pub start_pn: u32,
    pub size: u32,
    pub async_size: u32,
    pub prev_pn: u32,
    pub max_pages: u32,
}

impl ReadaheadState {
    pub const fn new(max_pages: u32) -> Self {
        Self {
            start_pn: 0,
            size: 0, // disabled readahead for now
            async_size: 0,
            prev_pn: 0,
            max_pages,
        }
    }

    // NOTE: these codes are generated by copilot
    // ---------------------------------------------------------------
    /// update readahead window on cache miss
    pub fn cache_miss_update_window(&mut self, trigger_pn: u32, req_size: u32) {
        // 1. 计算基准大小: size = req_size * 2 (or 4)
        let scaled_size = req_size.saturating_mul(INIT_RA_SCALE);

        // 2. 对齐优化 (向上取整到 2 的幂)
        // 注意: next_power_of_two() 在 0 时行为需注意，但 req_size 通常 > 0
        let mut new_size = scaled_size.next_power_of_two();

        // 3. 限制范围: [MIN, MAX]
        new_size = new_size.clamp(RA_MIN_PAGES, self.max_pages);

        // 4. 更新状态
        self.start_pn = trigger_pn; // 窗口起点 = 当前缺页位置
        self.size = new_size;

        // 5. 开启流水线: 初始阶段 async_size = size
        self.async_size = new_size;
    }

    /// 分支 2: 后续预读 (Subsequent Readahead / Ramp Up)
    /// 触发场景: 命中 PG_readahead 标记
    /// 论文来源:
    pub fn subsequent_readahead(&mut self) {
        // 1. 推进窗口起点: 新起点 = 旧起点 + 旧大小
        // 必须在更新 self.size 之前执行这一步
        self.start_pn = self.start_pn.saturating_add(self.size);
        // 2. 指数倍增: size = prev_size * 2
        let mut new_size = self.size.saturating_mul(RAMP_UP_SCALE);
        // 3. 限制上限
        new_size = new_size.min(self.max_pages);
        // 4. 更新大小
        self.size = new_size;
        // 5. 保持流水线: async_size = size
        self.async_size = new_size;
    }

    /// [辅助] 获取需要打上 PG_readahead 标记的页号
    /// 公式: start + size - async_size
    pub const fn get_trigger_offset(&self) -> u32 {
        if self.size == 0 {
            return 0; // 此时不应该打标
        }
        self.start_pn + self.size - self.async_size
    }

    /// [辅助] 在 read 结束时更新 prev_pn
    pub const fn update_history(&mut self, last_read_pn: u32) {
        self.prev_pn = last_read_pn;
    }

    // end of copilot generated code
    // ---------------------------------------------------------------
}

pub(super) trait Readahead {
    /// find cache from cache
    fn find_page_from_cache<'a>(
        &self,
        caches: &'a mut LruCache<u32, PageCache>,
        pn: u32,
    ) -> Option<(&'a mut PageCache, Option<u32>)>;
}

impl Readahead for CachedFile {
    fn find_page_from_cache<'a>(
        &self,
        caches: &'a mut LruCache<u32, PageCache>,
        pn: u32,
    ) -> Option<(&'a mut PageCache, Option<u32>)> {
        match caches.get_mut(&pn) {
            Some(cache) => {
                let mut new_pg_pn = None;
                if cache.pg_readahead {
                    cache.pg_readahead = false;
                    let mut ra = self.ra_state.lock();
                    ra.subsequent_readahead();
                    new_pg_pn = Some(ra.get_trigger_offset());
                }
                Some((cache, new_pg_pn))
            }
            None => None,
        }
    }
}

pub fn async_prefetch(
    cache_shared: Arc<CachedFileShared>,
    file: Arc<dyn FileNodeOps>,
    in_memory: bool,
    start_pn: u32,
    size: u32,
    async_pg_pn: u32,
) {
    let _ = sync_prefetch(
        &cache_shared,
        &FileNode::new(file),
        in_memory,
        start_pn,
        size,
        async_pg_pn,
    );
}

/// TODO: here we keep the lock for too long, but just to keep the same with [CachedFile::page_or_insert]
pub fn sync_prefetch(
    cache_shared: &CachedFileShared,
    file: &FileNode,
    in_memory: bool,
    start_pn: u32,
    size: u32,
    async_pg_pn: u32,
) -> VfsResult<()> {
    for pn in start_pn..(start_pn + size) {
        let mut caches = cache_shared.page_cache.lock();
        if caches.contains(&pn) {
            continue;
        }

        // Evict LRU page if cache is full
        // TODO: evict listners won't be notified
        if caches.len() == caches.cap().get() {
            if let Some((evict_pn, mut evicted_page)) = caches.pop_lru() {
                if evicted_page.dirty {
                    // We must drop the lock before writing back to avoid deadlock/blocking
                    // drop(caches);
                    file.write_at(evicted_page.data(), evict_pn as u64 * PAGE_SIZE as u64)?;
                }
            }
        }

        let mut page = PageCache::new()?;

        // Set the flag on the trigger page
        if pn == async_pg_pn {
            page.pg_readahead = true;
        }

        if in_memory {
            page.data().fill(0);
        } else {
            file.read_at(page.data(), pn as u64 * PAGE_SIZE as u64)?;
        }
        caches.put(pn, page);
    }
    Ok(())
}
